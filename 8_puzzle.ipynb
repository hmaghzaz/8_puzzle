{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Développement d'un Agent IA pour la Résolution d'un Puzzle 3x3 (8 Puzzle)\n",
    "\n",
    "Dans ce projet, nous allons créer un agent IA pour résoudre un puzzle de 3 lignes et 3 colonnes, où chaque case contient un chiffre de 1 à 8, sans répétition, avec une case vide. L'objectif de l'agent est de déplacer les cases en utilisant la case vide afin d'obtenir l'ordre croissant de 1 à 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environnemment\n",
    "\n",
    "| 1 | 2 | 3 |\n",
    "|---|---|---|\n",
    "| 4 | 5 | 6 |\n",
    "|   7| 8 |  |\n",
    "\n",
    "\n",
    "### Type de l'environnement \n",
    "1) Entièrement observable: l'agent a accès à toutes les informations nécessaires pour connaître l'état du puzzle dès la première observation.\n",
    "2) Déterministe : chaque action de l'agent entraine un état attendu, sans variations inattendues.\n",
    "3) Statique: l'état du l'environnement ne se change pas de manière autonome. c'est l'action executé par l'agent qui modifie la position des cases.\n",
    "4) Discret: dans le puzzle 3x3, il y a un nombre limité de cases et de configurations possibles pour les chiffres et la case vide. Chaque mouvement mène à un état distinct et identifiable du puzzle.\n",
    "5) Connu : l’agent sait que chaque action déplace la case vide dans une direction précise et produit un état bien défini, sans aucune incertitude.\n",
    "6) Séquentiel: les actions sont donc séquentielles car elles s'enchaînent logiquement et influencent les états futurs de l’environnement.\n",
    "7) Agent unique : il n’y a qu'un seul agent qui manipule les cases pour atteindre l’objectif. Aucun autre agent ne participe à la résolution du puzzle.  \n",
    "\n",
    "### Representation de l'evironnement :\n",
    "L'état du puzzle 3X3 peut être représenter par une matrice 2D, chaque cellule contient un nombre de 1 à 8 et une case vide représenter par 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'état initial\n",
    "initial_state = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 0, 8]  # 0 représente la case vide\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de solvabilité\n",
    "\n",
    "Il n'est pas possible de résoudre une instance de 8 puzzle si le nombre d'inversions est impair dans l'état d'entrée.\n",
    "\n",
    "| 1 | 2 | 3 |\n",
    "|---|---|---|\n",
    "| 4 | 5 | 6 |\n",
    "|   | 8 | 7 |\n",
    "\n",
    "\n",
    "Écrivez-le de façon linéaire, 1,2,3,4,5,6,8,7 - Ne tenez pas compte de la tuile vide.\n",
    "\n",
    "Trouvez maintenant le nombre d'inversions, en comptant les tuiles qui précèdent une autre tuile avec un nombre inférieur.\n",
    "\n",
    "Dans notre cas, 1,2,3,4,5,6,7 a 0 inversion, et 8 a 1 inversion car il précède le chiffre 7.\n",
    "\n",
    "Le nombre total d'inversions est de 1 (nombre impair) et le puzzle est donc insoluble.\n",
    "\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "| 5 | 2 | 8 |\n",
    "|---|---|---|\n",
    "| 4 | 1 | 7 |\n",
    "|   | 3 | 6 |\n",
    "\n",
    "5 précède 1,2,3,4 - 4 inversions\n",
    "\n",
    "2 précède 1 - 1 inversion\n",
    "\n",
    "8 précède 1,3,4,6,7 - 5 inversions\n",
    "\n",
    "4 précèdent 1,3 - 2 inversions\n",
    "\n",
    "1 précède aucun - 0 inversions\n",
    "\n",
    "7 précède 3,4 - 2 inversions\n",
    "\n",
    "3 précède aucun - 0 inversions\n",
    "\n",
    "6 précède aucun - 0 inversions\n",
    "\n",
    "total des inversions 4+1+5+2+0+2+0+0 = 14 (nombre pair)\n",
    "Cette énigme peut donc être résolue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Environnemt\n",
    "\n",
    "La classe Environnement représente l'état d'un puzzle 3x3 et contient deux méthodes principales :\n",
    "\n",
    "<span style=\"color: orange; font-weight: 700\">is_goal</span> vérifie si l'état actuel correspond à l'état objectif (cases ordonnées de 1 à 8 avec une case vide).\n",
    "\n",
    "<span style=\"color: orange; font-weight: 700\">is_solvable</span> détermine si le puzzle est résolvable en comptant les inversions, ce qui indique la possibilité de résoudre l'état initial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environnement:\n",
    "\n",
    "    def __init__(self, initial_state):\n",
    "        # Initialisation de l'environnement par un état de départ.\n",
    "        self.state = initial_state\n",
    "\n",
    "    # Vérifier si l'état actuel est l'état objective\n",
    "    def is_goal(self, state):\n",
    "        goal_state = [\n",
    "            [1, 2, 3],\n",
    "            [4, 5, 6],\n",
    "            [7, 8, 0]\n",
    "        ]\n",
    "        return state == goal_state\n",
    "\n",
    "    def is_solvable(self):\n",
    "        # Aplatir l'état et retirer le zéro (case vide)\n",
    "        flat_puzzle = [num for row in self.state for num in row if num != 0]\n",
    "        inversions = 0\n",
    "\n",
    "        # Compter les inversions\n",
    "        for i in range(len(flat_puzzle)):\n",
    "            for j in range(i + 1, len(flat_puzzle)):\n",
    "                if flat_puzzle[i] > flat_puzzle[j]:\n",
    "                    inversions += 1\n",
    "\n",
    "        # Le puzzle est solvable si :\n",
    "        # - le nombre d'inversions est pair\n",
    "        return inversions % 2 == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test class Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [0, 8, 7]\n",
    "]\n",
    "environnement = Environnement(initial_state)\n",
    "assert environnement.is_solvable() == False, f\"Erreur l'état doit être insoulvable\"\n",
    "print(f\"l'état founrie n'est pas soulvable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Capteur\n",
    "\n",
    "La classe Capteur fournit à l'agent les informations sur l'état actuel du puzzle et la position de la case vide en accédant directement à l'environnement. Elle permet ainsi à l'agent de prendre des décisions en fonction de la configuration courante des cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capteur:\n",
    "\n",
    "    def __init__(self, environnement):\n",
    "        self.environnement = environnement\n",
    "\n",
    "    # Lire l'état actuel\n",
    "    def get_current_state(self):\n",
    "        return self.environnement.state\n",
    "\n",
    "    # Trouver la position de la case vide\n",
    "    def find_empty(self, state):\n",
    "        for i, row in enumerate(state):\n",
    "            if 0 in row:\n",
    "                # print(f\"la position de vide et {i, row.index(0)}\")\n",
    "                return i, row.index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de la class Capteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1 : Créer un état initial du puzzle\n",
    "initial_state = [\n",
    "    [1, 2, 3],\n",
    "    [4, 0, 5],  # 0 représente la case vide position (1,1)\n",
    "    [6, 7, 8]\n",
    "]\n",
    "\n",
    "# Créer l'Environnement\n",
    "environnement = Environnement(initial_state)\n",
    "\n",
    "# Créer le capteur\n",
    "capteur = Capteur(environnement)\n",
    "\n",
    "# Étape 4 : Tester la méthode lire_etat()\n",
    "etat = capteur.get_current_state()\n",
    "assert etat == initial_state, f\"Erreur : l'état lu est {etat}, attendu {initial_state}\"\n",
    "\n",
    "# Étape 5 : Tester la méthode position_vide()\n",
    "position_vide = capteur.find_empty(etat)\n",
    "assert position_vide == (\n",
    "    1, 1), f\"Erreur : position vide est {position_vide}, attendu (1, 1)\"\n",
    "\n",
    "print(f\"Etat initial est : {initial_state}\")\n",
    "\n",
    "print(f\"position vide est : {position_vide}\")\n",
    "\n",
    "print(\"Tous les tests du capteur ont réussi !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Actionneur\n",
    "La classe Actionneur permet à l'agent de générer les états voisins possibles en déplaçant la case vide du puzzle dans les quatre directions (haut, bas, gauche, droite). Elle vérifie que les mouvements restent dans les limites et crée de nouveaux états en échangeant les cases. L’actionneur met également à jour l'état de l'environnement avec l'état sélectionné pour le prochain mouvement de l'agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actionneur:\n",
    "    def __init__(self, environnement, capteur):\n",
    "        self.environnement = environnement\n",
    "        self.capteur = capteur\n",
    "\n",
    "    # Générer les états suivants\n",
    "    def generate_next_states(self, state):\n",
    "        states = []\n",
    "        # Utiliser self pour accéder à capteur\n",
    "        row, col = self.capteur.find_empty(state)\n",
    "\n",
    "        # Haut, bas, gauche, droite\n",
    "        directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "\n",
    "        for d_row, d_col in directions:\n",
    "            new_row, new_col = row + d_row, col + d_col\n",
    "            if 0 <= new_row < 3 and 0 <= new_col < 3:  # Assurer que le mouvement reste dans les limites\n",
    "                new_state = [r[:] for r in state]  # Créer une copie de l'état\n",
    "                # Échanger les cases\n",
    "                new_state[row][col], new_state[new_row][new_col] = new_state[new_row][new_col], new_state[row][col]\n",
    "                states.append(new_state)\n",
    "\n",
    "        return states\n",
    "\n",
    "    # Mettre à jour l'état de l'environnement\n",
    "    def update_environment(self, new_state):\n",
    "        self.environnement.state = new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Actionneur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test du nombre d'états possibles est bien passé !\n",
      "Test de correspondance des états est bien réussi !\n",
      "Test de mise à jour de l'état de l'environnement est bien passé !\n",
      "Tous les tests sont passés avec succès !\n"
     ]
    }
   ],
   "source": [
    "# environnemt est déjà initialiser dans le Test capteur\n",
    "# capteur est déjà initialiser dans le Test capteur\n",
    "\n",
    "###### Rappel de l'état initial ###########\n",
    "\n",
    "# initial_state = [\n",
    "#     [1, 2, 3],\n",
    "#     [4, 0, 5],\n",
    "#     [6, 7, 8]\n",
    "# ]\n",
    "\n",
    "###########################################\n",
    "\n",
    "\n",
    "# Initialisation de l'Actionneur\n",
    "actionneur = Actionneur(environnement, capteur)\n",
    "\n",
    "state = capteur.get_current_state()\n",
    "\n",
    "# Générer les états\n",
    "states = actionneur.generate_next_states(state)\n",
    "\n",
    "# État suivants attendus après les différentes actions\n",
    "expected_states = [\n",
    "    [\n",
    "        [1, 0, 3],\n",
    "        [4, 2, 5],\n",
    "        [6, 7, 8]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 7, 5],\n",
    "        [6, 0, 8]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [0, 4, 5],\n",
    "        [6, 7, 8]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 0],\n",
    "        [6, 7, 8]\n",
    "    ]\n",
    "]\n",
    "\n",
    "# État attendu pour le test de mise à jour\n",
    "new_state = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 0],\n",
    "    [6, 7, 8]\n",
    "]\n",
    "\n",
    "\n",
    "# Vérifier que le nombre d'états générés correspond au nombre d'états attendus\n",
    "assert len(states) == len(expected_states), \"Nombre de states incorrect\"\n",
    "print(\"Test du nombre d'états possibles est bien passé !\")\n",
    "\n",
    "# Vérifier chaque état généré par rapport à chaque état attendu\n",
    "for state in states:\n",
    "    assert state in expected_states, f\"État inattendu : {state}\"\n",
    "print(\"Test de correspondance des états est bien réussi !\")\n",
    "\n",
    "# Appeler la méthode update_environment avec le nouvel état\n",
    "actionneur.update_environment(new_state)\n",
    "\n",
    "# Vérifier que l'état de l'environnement a été mis à jour correctement\n",
    "assert environnement.state == new_state, \"L'état de l'environnement n'a pas été mis à jour correctement\"\n",
    "print(\"Test de mise à jour de l'état de l'environnement est bien passé !\")\n",
    "\n",
    "print(\"Tous les tests sont passés avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Agent\n",
    "\n",
    "L'agent est un agent basé sur des objectifs avec une représentation atomique, utilisant l'algorithme A pour résoudre un puzzle 3x3. Il se sert de la distance de Manhattan comme heuristique afin de guider la recherche d'une solution optimale en explorant les états voisins de manière prioritaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La Distance de Manhattan\n",
    "[![Video Title](https://img.youtube.com/vi/p3HbBlcXDTE/0.jpg)](https://www.youtube.com/watch?v=p3HbBlcXDTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithme A* avec la recherhce heuristique\n",
    "\n",
    "[![Video Title](https://img.youtube.com/vi/5RcAYMzT6jY/0.jpg)](https://www.youtube.com/watch?v=5RcAYMzT6jY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <span style=\"color: orange; font-weight: 700\">La fonction manhattan</span> calcule la distance totale que chaque tuile (excepté la case vide) doit parcourir pour atteindre sa position correcte dans le puzzle 8. Cela est réalisé en itérant sur chaque case, en déterminant sa position actuelle et sa position cible, puis en accumulant les distances nécessaires. Cette heuristique aide l'algorithme A* à évaluer l'efficacité des états explorés lors de la recherche d'une solution au puzzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappop, heappush\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, environnement, capteur, actionneur):\n",
    "        self.environnement = environnement\n",
    "        self.capteur = capteur\n",
    "        self.actionneur = actionneur\n",
    "\n",
    "    # calcule la distance totale de manhattan qui sera utiliser par l'algorithme A* pour aider à prendre des décisions optimales lors de la recherche d'une solution.\n",
    "    def manhattan(self, puzzle):\n",
    "        dist = 0\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                value = puzzle[i][j]\n",
    "                if value != 0:\n",
    "                    target_row = (value - 1) // 3\n",
    "                    target_col = (value - 1) % 3\n",
    "                    dist += abs(i - target_row) + abs(j - target_col)\n",
    "        return dist\n",
    "\n",
    "    def solve(self):\n",
    "\n",
    "        # Check if the puzzle is solvable\n",
    "        if not self.environnement.is_solvable():\n",
    "            return None  # Return if the puzzle is not solvable\n",
    "\n",
    "        # ---> une liste utilisée comme une file de priorité pour les états à explorer, initialement vide.\n",
    "        open_set = []\n",
    "        initial_state = self.capteur.get_current_state()\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------\n",
    "        #  heappush import depuis la librairie heapq                                                     |\n",
    "        #  La fonction heappush ajoute l'état initial à open_set, avec :                                 |\n",
    "        #  (self.manhattan(initial_state) : La distance heuristique de Manhattan pour cet état,          |\n",
    "        #  0 : Le coût actuel (0 pour l'état initial),                                                   |\n",
    "        #  initial_state : L'état lui-même,                                                              |\n",
    "        #  []: Un chemin vide (pas encore de mouvements).                                                |\n",
    "        #                                                                                                |\n",
    "        heappush(open_set, (self.manhattan(\n",
    "            initial_state), 0, initial_state, []))  # |\n",
    "        # ------------------------------------------------------------------------------------------------\n",
    "        # ---->  un ensemble qui stocke les états déjà visités pour éviter les répétitions.\n",
    "        seen = set()\n",
    "\n",
    "        while open_set:  # ----> Cette boucle continue tant qu'il y a des états à explorer dans open_set\n",
    "            # heappop retire l'état avec le coût le plus bas de open_set et le stocke dans les variables :\n",
    "            # _ : la distance heuristique (non utilisée ici),\n",
    "            # cost : le coût actuel pour atteindre cet état,\n",
    "            # current : l'état courant du puzzle,\n",
    "            # path : le chemin parcouru pour atteindre cet état.\n",
    "\n",
    "            # ---> l'algorithm A* nous fourni une état après faire des calcule\n",
    "            _, cost, current, path = heappop(open_set)\n",
    "\n",
    "            # Vérification si l'état voisin est égal à notre état objectif.\n",
    "            if self.environnement.is_goal(current):\n",
    "                # ----> mettre à jour l'état de l'environnement\n",
    "                self.actionneur.update_environment(neighbor_state)\n",
    "                # ---> afficher l'état actuel de l'environnement après la mise à jour\n",
    "                print(f\"Etat final : {capteur.get_current_state()}\")\n",
    "                # ----> afficher le coût total\n",
    "                print(f\"le coût total est : {cost}\")\n",
    "                return path   # ----> Retourner le chemin\n",
    "\n",
    "            # --->  ajouter l'état actuel à un ensemble \"seen\" afin de garder une trace des états déjà visités par l'agent. afin d'éviter des cycles infinis\n",
    "            seen.add(tuple(map(tuple, current)))\n",
    "            for neighbor_state in self.actionneur.generate_next_states(current):\n",
    "                neighbor_tuple = tuple(map(tuple, neighbor_state))\n",
    "                if neighbor_tuple not in seen:\n",
    "                    heappush(open_set, (cost + 1 + self.manhattan(neighbor_state),   # ----> on ajoute les états voisins pour fournir à l'algorithme A* des état pour atteindre l'état objectif\n",
    "                             cost + 1, neighbor_state, path + [neighbor_state]))\n",
    "\n",
    "        return None  # Si aucune solution n'est trouvée, retourner None et les étapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Class Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etat final : [[1, 2, 3], [4, 5, 6], [7, 8, 0]]\n",
      "le coût total est : 2\n",
      "Test réussi ! L'agent a trouvé le chemin vers l'état objectif.\n",
      "Étapes pour atteindre l'état objectif:\n",
      "[1, 2, 3]\n",
      "[4, 0, 6]\n",
      "[7, 5, 8]\n",
      "\n",
      "[1, 2, 3]\n",
      "[4, 5, 6]\n",
      "[7, 0, 8]\n",
      "\n",
      "[1, 2, 3]\n",
      "[4, 5, 6]\n",
      "[7, 8, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# État initial facile pour le test\n",
    "initial_state = [\n",
    "    [1, 2, 3],\n",
    "    [4, 0, 6],\n",
    "    [7, 5, 8]\n",
    "]\n",
    "\n",
    "# Initialisation de l'environnement et des composants\n",
    "environnement = Environnement(initial_state)\n",
    "capteur = Capteur(environnement)\n",
    "actionneur = Actionneur(environnement, capteur)\n",
    "agent = Agent(environnement, capteur, actionneur)\n",
    "\n",
    "# Résoudre le puzzle\n",
    "path = agent.solve()\n",
    "\n",
    "# Vérifier que le dernier état dans les étapes correspond à l'état objectif\n",
    "goal_state = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 0]\n",
    "]\n",
    "\n",
    "# Test: vérifier si le chemin amène à l'état objectif\n",
    "assert path[-1] == goal_state, \"L'agent n'a pas atteint l'état objectif.\"\n",
    "print(\"Test réussi ! L'agent a trouvé le chemin vers l'état objectif.\")\n",
    "\n",
    "\n",
    "# Imprimer les étapes de la solution\n",
    "print(\"Étapes pour atteindre l'état objectif:\")\n",
    "path.insert(0, initial_state)\n",
    "for step in path:\n",
    "    for row in step:\n",
    "        print(row)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class PuzzleService\n",
    "\n",
    "La classe PuzzleService est dédiée à l'affichage graphique d'un puzzle de type 3x3. Elle contient deux méthodes principales : display_puzzle, qui affiche un état donné du puzzle sur une grille, et display_steps, qui montre une séquence d'états pas à pas avec une pause d'une seconde entre chaque étape. Cette classe facilite ainsi la visualisation des déplacements dans le puzzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "class PuzzleService:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def display_puzzle(self, state):\n",
    "        puzzle_grid = np.array(state)\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        ax.matshow(np.zeros((3, 3)), cmap=\"gray\")\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if puzzle_grid[i, j] == 0:\n",
    "                    ax.text(j, i, \"\", va='center', ha='center', fontsize=30, color='red', bbox=dict(\n",
    "                        facecolor='white', edgecolor='black'))\n",
    "                else:\n",
    "                    ax.text(j, i, str(puzzle_grid[i, j]), va='center', ha='center', fontsize=30, bbox=dict(\n",
    "                        facecolor='white', edgecolor='black'))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.show()\n",
    "\n",
    "    def display_steps(self, steps):\n",
    "        for step in steps:\n",
    "            self.display_puzzle(step)\n",
    "            sleep(1)  # Pause de 1 seconde entre les étapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Main:\n",
    "    def __init__(self, initial_state):\n",
    "        self.environment = Environnement(initial_state)\n",
    "        self.capteur = Capteur(self.environment)\n",
    "        self.actionneur = Actionneur(self.environment, self.capteur)\n",
    "        self.agent = Agent(self.environment, self.capteur, self.actionneur)\n",
    "        self.puzzle_service = PuzzleService()\n",
    "        self.first_state = initial_state\n",
    "\n",
    "    def run(self):\n",
    "        solution = self.agent.solve()\n",
    "\n",
    "        if solution:\n",
    "            print(\"Solution trouvée !\")\n",
    "            self.puzzle_service.display_puzzle(self.first_state)\n",
    "            self.puzzle_service.display_steps(solution)\n",
    "        else:\n",
    "            print(\"Pas de solution possible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: brown; font-weight: 900\"> Spécification PEAS (Performance Measure, Environement, Actuators, Sensors) <span>\n",
    "\n",
    "<span style=\"color: orange; font-weight: 700\">1. Performance Measure (Mesure de Performance)</span><br/>\n",
    "<br/>\n",
    "L'agent vise à résoudre le puzzle en atteignant l'état objectif (grille ordonnée de 1 à 8 avec une case vide). Les critères de performance incluent :<br/>\n",
    "<ul>\n",
    "<li><strong>Minimiser le nombre de déplacements </strong> pour atteindre la solution (coût total).</li>\n",
    "<li><strong> Minimiser le temps d'exécution </strong> ou la profondeur de recherche pour une résolution rapide.</li>\n",
    "<li><strong>Optimisation de la mémoire </strong> en évitant de revisiter des états déjà explorés, grâce à l’utilisation de la liste seen.</li>\n",
    "</ul>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-weight: 700\">2. Environment (Environnement)</span><br/>\n",
    "<br/>\n",
    "L'environnement du puzzle est :\n",
    "<ul>\n",
    "<li><strong>Entièrement observable :</strong> L'agent connaît l'intégralité de la grille à tout moment, y compris la position actuelle de chaque tuile et de la case vide.</li>\n",
    "<li><strong>Déterministe :</strong> Chaque action (déplacement d'une tuile) entraîne un changement de l'état du puzzle de manière prédictible.</li>\n",
    "<li><strong>Statique :</strong> L'environnement ne change pas de lui-même pendant que l'agent réfléchit ; il n’y a pas de mouvements indépendants des tuiles.</li>\n",
    "<li><strong>Discret :</strong> L'environnement est limité à des états distincts dans une grille de 3x3, avec un ensemble fixe de positions pour chaque tuile.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-weight: 700\">3. Actuators (Actionneurs)</span><br/>\n",
    "<br/>\n",
    "Les actionneurs de l’agent permettent de manipuler les tuiles du puzzle en fonction de la position de la case vide :\n",
    "<ul>\n",
    "<li><strong>Déplacer la case vide :</strong> L'agent peut déplacer la case vide vers le haut, le bas, la gauche ou la droite, à condition que ces mouvements soient possibles dans les limites de la grille.</li>\n",
    "<li><strong>Génération des états voisins :</strong> À partir de l’état actuel, l’agent génère de nouveaux états en effectuant les déplacements possibles, évaluant chaque état pour déterminer la meilleure trajectoire.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-weight: 700\">4. Sensors (Capteurs)</span><br/>\n",
    "<br/>\n",
    "Les capteurs de l'agent incluent :\n",
    "<ul>\n",
    "<li><strong>Lecture de l’état actuel :</strong> Le capteur lit la configuration complète de la grille (position de chaque tuile et de la case vide) pour analyser la situation.</li>\n",
    "<li><strong>Capteur de position vide :</strong> Identifie la position de la case vide, indispensable pour calculer les mouvements possibles.</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
